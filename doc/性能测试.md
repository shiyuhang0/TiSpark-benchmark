# TiSpark 准备
1. 下载 tispark 符合版本的 jar 包
2. 配置 spark.defaults.conf
```
spark.master                      spark://{master}:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"

spark.sql.extensions  org.apache.spark.sql.TiExtensions
spark.tispark.pd.addresses  {pd_address}
spark.sql.catalog.tidb_catalog org.apache.spark.sql.catalyst.catalog.TiCatalog
spark.sql.catalog.tidb_catalog.pd.addresses {pd_address}
# spark.executor.cores 1
# spark.executor.memory 1g
# spark.ui.port 3000
```

# HDFS 写入 TiDB
请确保已经将数据 put 到 HDFS 中。

- 使用 TiSpark 写入: 参考 script 下的 [tispark_write.scala](../script/tispark_write.scala)
- 使用 Spark JDBC 写入：参考 script 下的 [jdbc_write.scala](../script/jdbc_write.scala)


# 删除 TiDB
参考 script 下的 [tispark_delete.scala](../script/tispark_delete.scala)

